{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "20866888-e8c5-4a63-b80d-6fad1753fa0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset           Top-1   Top-5      Δ1      Δ5\n",
      "-----------------------------------------------\n",
      "Clean             74.26   93.52\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "# 0. Device & model\n",
    "device    = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model     = models.densenet121(weights='IMAGENET1K_V1').to(device)\n",
    "model.eval()\n",
    "\n",
    "# Define preprocessing transforms (add resize for ResNet-34)\n",
    "mean_norms = np.array([0.485, 0.456, 0.406])\n",
    "std_norms = np.array([0.229, 0.224, 0.225])\n",
    "plain_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Ensure image size matches ResNet-34 input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=mean_norms, std=std_norms)\n",
    "])\n",
    "\n",
    "# Load test dataset\n",
    "dataset_path = \"./TestDataSet\"  # Update with actual path\n",
    "dataset = ImageFolder(root=dataset_path, transform=plain_transforms)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# Load label mappings from JSON file\n",
    "with open(\"./TestDataSet/labels_list.json\", \"r\") as f:  # Update with actual JSON path\n",
    "    label_mappings = json.load(f)\n",
    "\n",
    "# Create a mapping from ImageFolder indices to ImageNet indices\n",
    "# ImageFolder assigns indices based on folder names (alphabetical order)\n",
    "folder_to_idx = {class_name: idx for idx, class_name in enumerate(dataset.classes)}\n",
    "\n",
    "# Parse the JSON entries and sort by ImageNet index\n",
    "label_mappings_parsed = []\n",
    "for entry in label_mappings:\n",
    "    imagenet_idx, class_name = entry.split(\": \")\n",
    "    label_mappings_parsed.append((int(imagenet_idx), class_name))\n",
    "label_mappings_parsed.sort(key=lambda x: x[0])  # Sort by ImageNet index\n",
    "\n",
    "# Sort folder names (WNIDs) to match ImageFolder's ordering\n",
    "sorted_folders = sorted(dataset.classes)\n",
    "\n",
    "# Map ImageFolder indices to ImageNet indices\n",
    "# Assume the sorted WNIDs correspond to the sorted ImageNet indices\n",
    "idx_to_imagenet_idx = {}\n",
    "for folder_idx, (imagenet_idx, class_name) in enumerate(label_mappings_parsed):\n",
    "    if folder_idx < len(sorted_folders):\n",
    "        idx_to_imagenet_idx[folder_idx] = imagenet_idx\n",
    "    else:\n",
    "        print(f\"Warning: More ImageNet indices than folders. Extra entry: {imagenet_idx}: {class_name}\")\n",
    "\n",
    "# Debugging: Print the mapping\n",
    "#print(\"Mapping (ImageFolder idx -> ImageNet idx):\", idx_to_imagenet_idx)\n",
    "\n",
    "# Check for unmapped ImageFolder indices\n",
    "all_folder_indices = set(range(len(dataset.classes)))\n",
    "mapped_indices = set(idx_to_imagenet_idx.keys())\n",
    "unmapped_indices = all_folder_indices - mapped_indices\n",
    "if unmapped_indices:\n",
    "    print(f\"Unmapped ImageFolder indices: {unmapped_indices}\")\n",
    "    for idx in unmapped_indices:\n",
    "        print(f\"Index {idx} corresponds to folder: {dataset.classes[idx]}\")\n",
    "\n",
    "# Function to compute top-k accuracy\n",
    "def compute_topk_accuracy(outputs, labels, k=1):\n",
    "    batch_size = labels.size(0)\n",
    "    _, pred = outputs.topk(k, dim=1, largest=True, sorted=True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(labels.view(1, -1).expand_as(pred))\n",
    "    correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
    "    return correct_k.mul_(100.0 / batch_size).item()\n",
    "\n",
    "\n",
    "\n",
    "# Evaluate model\n",
    "top1_correct = 0\n",
    "top5_correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in dataloader:\n",
    "        images = images.to(device)\n",
    "        # Map ImageFolder labels to ImageNet indices\n",
    "        imagenet_labels = torch.tensor([idx_to_imagenet_idx[label.item()] for label in labels]).to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        \n",
    "        # Compute top-1 and top-5 accuracy\n",
    "        top1_correct += compute_topk_accuracy(outputs, imagenet_labels, k=1)\n",
    "        top5_correct += compute_topk_accuracy(outputs, imagenet_labels, k=5)\n",
    "        total += 1\n",
    "\n",
    "# Calculate average accuracies\n",
    "top1_t1_accuracy = top1_correct / total\n",
    "top5_t1_accuracy = top5_correct / total\n",
    "\n",
    "\n",
    "results = {}\n",
    "results[\"Clean\"] = (top1_t1_accuracy, top5_t1_accuracy)\n",
    "\n",
    "# ###################################################################\n",
    "# #FGSM\n",
    "# FGSM = ImageFolder(root=\"./AdversarialTestSet1\", transform=plain_transforms)\n",
    "# F = DataLoader(FGSM, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Evaluate model\n",
    "# top1_correct = 0\n",
    "# top5_correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in F:\n",
    "#         images = images.to(device)\n",
    "#         # Map ImageFolder labels to ImageNet indices\n",
    "#         imagenet_labels = torch.tensor([idx_to_imagenet_idx[label.item()] for label in labels]).to(device)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "        \n",
    "#         # Compute top-1 and top-5 accuracy\n",
    "#         top1_correct += compute_topk_accuracy(outputs, imagenet_labels, k=1)\n",
    "#         top5_correct += compute_topk_accuracy(outputs, imagenet_labels, k=5)\n",
    "#         total += 1\n",
    "\n",
    "# # Calculate average accuracies\n",
    "# top1_t1_accuracy = top1_correct / total\n",
    "# top5_t1_accuracy = top5_correct / total\n",
    "\n",
    "# results[\"FGSM(Set 1)\"] = (top1_t1_accuracy, top5_t1_accuracy)\n",
    "\n",
    "# #PGD\n",
    "# PGD = ImageFolder(root=\"./AdversarialTestSet2\", transform=plain_transforms)\n",
    "# P = DataLoader(PGD, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Evaluate model\n",
    "# top1_correct = 0\n",
    "# top5_correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in P:\n",
    "#         images = images.to(device)\n",
    "#         # Map ImageFolder labels to ImageNet indices\n",
    "#         imagenet_labels = torch.tensor([idx_to_imagenet_idx[label.item()] for label in labels]).to(device)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "        \n",
    "#         # Compute top-1 and top-5 accuracy\n",
    "#         top1_correct += compute_topk_accuracy(outputs, imagenet_labels, k=1)\n",
    "#         top5_correct += compute_topk_accuracy(outputs, imagenet_labels, k=5)\n",
    "#         total += 1\n",
    "\n",
    "# # Calculate average accuracies\n",
    "# top1_t1_accuracy = top1_correct / total\n",
    "# top5_t1_accuracy = top5_correct / total\n",
    "\n",
    "# results[\"PGD(Set 2)\"] = (top1_t1_accuracy, top5_t1_accuracy)\n",
    "\n",
    "# #Patch\n",
    "# Patch = ImageFolder(root=\"./AdversarialTestSet4_loss_alpha\", transform=plain_transforms)\n",
    "# P = DataLoader(Patch, batch_size=32, shuffle=False, num_workers=4)\n",
    "\n",
    "# # Evaluate model\n",
    "# top1_correct = 0\n",
    "# top5_correct = 0\n",
    "# total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in P:\n",
    "#         images = images.to(device)\n",
    "#         # Map ImageFolder labels to ImageNet indices\n",
    "#         imagenet_labels = torch.tensor([idx_to_imagenet_idx[label.item()] for label in labels]).to(device)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "        \n",
    "#         # Compute top-1 and top-5 accuracy\n",
    "#         top1_correct += compute_topk_accuracy(outputs, imagenet_labels, k=1)\n",
    "#         top5_correct += compute_topk_accuracy(outputs, imagenet_labels, k=5)\n",
    "#         total += 1\n",
    "\n",
    "# # Calculate average accuracies\n",
    "# top1_t1_accuracy = top1_correct / total\n",
    "# top5_t1_accuracy = top5_correct / total\n",
    "\n",
    "# results[\"Patch(Set 3)\"] = (top1_t1_accuracy, top5_t1_accuracy)\n",
    "\n",
    "\n",
    "print(f\"{'Dataset':<15}{'Top-1':>8}{'Top-5':>8}{'Δ1':>8}{'Δ5':>8}\")\n",
    "print(\"-\"*47)\n",
    "for name, (t1, t5) in results.items():\n",
    "    print(f\"{name:<15}{t1:8.2f}{t5:8.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e50a556-7698-4ea8-9626-90d9619ea4a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Proj3 (env)",
   "language": "python",
   "name": "proj3-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
